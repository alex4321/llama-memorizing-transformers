# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_model_wrapper.ipynb.

# %% auto 0
__all__ = ['replace_llama_layer_with_memory']

# %% ../nbs/03_model_wrapper.ipynb 1
from dataclasses import dataclass
from typing import Dict, Any, Union
from transformers.models.llama import LlamaModel
from .memorizing_block import MemorizingLlamaDecoderLayer
from .memory_collection import BaseMemoryCollection, CosineKnnMemoryCollection
from .context_choice import BaseContextChoice, ContextChoiceConstant, ContextChoiceLinear

# %% ../nbs/03_model_wrapper.ipynb 3
def replace_llama_layer_with_memory(model: LlamaModel,
                                    layer_index: int,
                                    context: BaseContextChoice,
                                    memory: BaseMemoryCollection) -> LlamaModel:
    original_layer = model.layers[layer_index]
    new_layer = MemorizingLlamaDecoderLayer(
        module=original_layer,
        context_choice=context.to(model.device),
        memory=memory,
        device=model.device
    )
    model.layers[layer_index] = new_layer
    model._memorizing_patch = True
    return model
