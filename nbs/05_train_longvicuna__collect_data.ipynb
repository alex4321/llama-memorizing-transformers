{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex4321/anaconda3/envs/longdocchat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from markdownify import markdownify\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inidivudual datasets preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following datasets:\n",
    "- OpenAssistant + Alpaca + Gpt4All to keep the original instruction chat-like behaviour\n",
    "- a few other datasets to make model be able to operate the long-term memory\n",
    "    - booksum - to generate literature summaries\n",
    "    - govreport - same, but for formal texts\n",
    "    - qasper - to operate a memory for QA tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/alex4321/.cache/huggingface/datasets/OpenAssistant___parquet/OpenAssistant--oasst1-2960c57d7e52ab15/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['message_id', 'parent_id', 'user_id', 'created_date', 'text', 'role', 'lang', 'review_count', 'review_result', 'deleted', 'rank', 'synthetic', 'model_name', 'detoxify', 'message_tree_id', 'tree_state', 'emojis', 'labels'],\n",
       "        num_rows: 84437\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['message_id', 'parent_id', 'user_id', 'created_date', 'text', 'role', 'lang', 'review_count', 'review_result', 'deleted', 'rank', 'synthetic', 'model_name', 'detoxify', 'message_tree_id', 'tree_state', 'emojis', 'labels'],\n",
       "        num_rows: 4401\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_oasst1 = load_dataset(\"OpenAssistant/oasst1\")\n",
    "dataset_oasst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _oasst1_parent2children(df_oasst1):\n",
    "    parent_id_2_children = {}\n",
    "    for _, row in df_oasst1.iterrows():\n",
    "        if row[\"parent_id\"] not in parent_id_2_children:\n",
    "            parent_id_2_children[row[\"parent_id\"]] = []\n",
    "        parent_id_2_children[row[\"parent_id\"]].append(row[\"message_id\"])\n",
    "    return parent_id_2_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _oasst1_tree(parent_id_2_children, root):\n",
    "    children = parent_id_2_children.get(root, [])\n",
    "    result = {}\n",
    "    for child_id in children:\n",
    "        result[child_id] = _oasst1_tree(parent_id_2_children, child_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _oasst1_tree2list(tree):\n",
    "    if len(tree) == 0:\n",
    "        return [[]]\n",
    "    result = []\n",
    "    for child_id, subtree in tree.items():\n",
    "        for row in _oasst1_tree2list(subtree):\n",
    "            result.append([child_id] + row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oasst1_2_messages(df_oasst1):\n",
    "    dialogue_message_ids = _oasst1_tree2list(\n",
    "        _oasst1_tree(\n",
    "            _oasst1_parent2children(df_oasst1),\n",
    "            None\n",
    "        )\n",
    "    )\n",
    "    message_id2index = {mid: i for i, mid in df_oasst1[\"message_id\"].to_dict().items()}\n",
    "    df = df_oasst1[[\"text\", \"role\"]]\n",
    "    indices = [\n",
    "        [\n",
    "            message_id2index[mid]\n",
    "            for mid in message_ids\n",
    "        ]\n",
    "        for message_ids in dialogue_message_ids\n",
    "    ]\n",
    "    return indices, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text</th>\n",
       "      <th>role</th>\n",
       "      <th>lang</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_result</th>\n",
       "      <th>deleted</th>\n",
       "      <th>rank</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>model_name</th>\n",
       "      <th>detoxify</th>\n",
       "      <th>message_tree_id</th>\n",
       "      <th>tree_state</th>\n",
       "      <th>emojis</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>None</td>\n",
       "      <td>c3fe8c76-fc30-4fa7-b7f8-c492f5967d18</td>\n",
       "      <td>2023-02-05T14:23:50.983374+00:00</td>\n",
       "      <td>Can you write a short introduction about the r...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.00044308538781479, 'severe_toxi...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1', '_skip_reply', '_skip_ranking'...</td>\n",
       "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c8e83833-ecbc-44fe-b6db-735228c25a1c</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>2c96e467-66f0-4be7-9693-bda51356a424</td>\n",
       "      <td>2023-02-06T13:50:44.657083+00:00</td>\n",
       "      <td>\"Monopsony\" refers to a market structure where...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.00026396565954200923, 'severe_t...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1', '_skip_labeling'], 'count': [3...</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6708c47f-05c9-4346-b3d2-40b2bd24fde4</td>\n",
       "      <td>c8e83833-ecbc-44fe-b6db-735228c25a1c</td>\n",
       "      <td>2c96e467-66f0-4be7-9693-bda51356a424</td>\n",
       "      <td>2023-02-06T18:48:49.391686+00:00</td>\n",
       "      <td>Now explain it to a dog</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.03648477792739868, 'severe_toxi...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>None</td>\n",
       "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343ee2d4-87ae-41fd-a768-bdd65959dc4a</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>49ddcb0d-6588-43bd-858d-19c577f12e7b</td>\n",
       "      <td>2023-02-06T13:37:56.044680+00:00</td>\n",
       "      <td>Monopsony is a market structure in which there...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.0008866374846547842, 'severe_to...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1', '_skip_reply', '_skip_labeling...</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18145bf4-37fd-4ac0-80f5-6108b5f2b365</td>\n",
       "      <td>343ee2d4-87ae-41fd-a768-bdd65959dc4a</td>\n",
       "      <td>e10e99a0-38ac-4b07-bf5d-4427696e4e0d</td>\n",
       "      <td>2023-02-06T18:52:51.428543+00:00</td>\n",
       "      <td>How can one fight back when a monospony had be...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.0009362137061543763, 'severe_to...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1'], 'count': [1]}</td>\n",
       "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             message_id                             parent_id   \n",
       "0  6ab24d72-0181-4594-a9cd-deaf170242fb                                  None  \\\n",
       "1  c8e83833-ecbc-44fe-b6db-735228c25a1c  6ab24d72-0181-4594-a9cd-deaf170242fb   \n",
       "2  6708c47f-05c9-4346-b3d2-40b2bd24fde4  c8e83833-ecbc-44fe-b6db-735228c25a1c   \n",
       "3  343ee2d4-87ae-41fd-a768-bdd65959dc4a  6ab24d72-0181-4594-a9cd-deaf170242fb   \n",
       "4  18145bf4-37fd-4ac0-80f5-6108b5f2b365  343ee2d4-87ae-41fd-a768-bdd65959dc4a   \n",
       "\n",
       "                                user_id                      created_date   \n",
       "0  c3fe8c76-fc30-4fa7-b7f8-c492f5967d18  2023-02-05T14:23:50.983374+00:00  \\\n",
       "1  2c96e467-66f0-4be7-9693-bda51356a424  2023-02-06T13:50:44.657083+00:00   \n",
       "2  2c96e467-66f0-4be7-9693-bda51356a424  2023-02-06T18:48:49.391686+00:00   \n",
       "3  49ddcb0d-6588-43bd-858d-19c577f12e7b  2023-02-06T13:37:56.044680+00:00   \n",
       "4  e10e99a0-38ac-4b07-bf5d-4427696e4e0d  2023-02-06T18:52:51.428543+00:00   \n",
       "\n",
       "                                                text       role lang   \n",
       "0  Can you write a short introduction about the r...   prompter   en  \\\n",
       "1  \"Monopsony\" refers to a market structure where...  assistant   en   \n",
       "2                            Now explain it to a dog   prompter   en   \n",
       "3  Monopsony is a market structure in which there...  assistant   en   \n",
       "4  How can one fight back when a monospony had be...   prompter   en   \n",
       "\n",
       "   review_count review_result  deleted  rank  synthetic model_name   \n",
       "0             3          True    False   NaN      False       None  \\\n",
       "1             3          True    False   0.0      False       None   \n",
       "2             3          True    False   NaN      False       None   \n",
       "3             3          True    False   1.0      False       None   \n",
       "4             3          True    False   NaN      False       None   \n",
       "\n",
       "                                            detoxify   \n",
       "0  {'toxicity': 0.00044308538781479, 'severe_toxi...  \\\n",
       "1  {'toxicity': 0.00026396565954200923, 'severe_t...   \n",
       "2  {'toxicity': 0.03648477792739868, 'severe_toxi...   \n",
       "3  {'toxicity': 0.0008866374846547842, 'severe_to...   \n",
       "4  {'toxicity': 0.0009362137061543763, 'severe_to...   \n",
       "\n",
       "                        message_tree_id        tree_state   \n",
       "0  6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export  \\\n",
       "1  6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "2  6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "3  6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "4  6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "\n",
       "                                              emojis   \n",
       "0  {'name': ['+1', '_skip_reply', '_skip_ranking'...  \\\n",
       "1  {'name': ['+1', '_skip_labeling'], 'count': [3...   \n",
       "2                                               None   \n",
       "3  {'name': ['+1', '_skip_reply', '_skip_labeling...   \n",
       "4                     {'name': ['+1'], 'count': [1]}   \n",
       "\n",
       "                                              labels  \n",
       "0  {'name': ['spam', 'lang_mismatch', 'pii', 'not...  \n",
       "1  {'name': ['spam', 'fails_task', 'lang_mismatch...  \n",
       "2  {'name': ['spam', 'lang_mismatch', 'pii', 'not...  \n",
       "3  {'name': ['spam', 'fails_task', 'lang_mismatch...  \n",
       "4  {'name': ['spam', 'lang_mismatch', 'pii', 'not...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oasst1_train = pd.DataFrame(dataset_oasst1[\"train\"])\n",
    "df_oasst1_train = df_oasst1_train.loc[df_oasst1_train[\"review_result\"].fillna(False)]\n",
    "df_oasst1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text</th>\n",
       "      <th>role</th>\n",
       "      <th>lang</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_result</th>\n",
       "      <th>deleted</th>\n",
       "      <th>rank</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>model_name</th>\n",
       "      <th>detoxify</th>\n",
       "      <th>message_tree_id</th>\n",
       "      <th>tree_state</th>\n",
       "      <th>emojis</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>None</td>\n",
       "      <td>845cba79-9d16-4eb8-ab63-982fe8403c62</td>\n",
       "      <td>2023-02-08T11:55:51.852473+00:00</td>\n",
       "      <td>–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —è–∑—ã–∫–µ swift, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.0025964330416172743, 'severe_to...</td>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1', '_skip_reply', '_skip_ranking'...</td>\n",
       "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a38b3d1c-256f-47c5-ab68-c9ab766bad84</td>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>abbc8a37-2db7-4af5-9df1-b0582d2e3d93</td>\n",
       "      <td>2023-03-16T22:29:28.829265+00:00</td>\n",
       "      <td>–í–æ—Ç —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–∞—Å—Å–∏–≤ —Ü–µ–ª—ã—Ö —á–∏...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.0003634887107182294, 'severe_to...</td>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1', '_skip_labeling'], 'count': [1...</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9cf52b01-0582-46aa-9ad2-70827dce87ed</td>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>a3e19dd4-34cd-48f0-8912-a2003b22c334</td>\n",
       "      <td>2023-02-11T09:57:39.207727+00:00</td>\n",
       "      <td>–í–æ—Ç —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞ —è–∑—ã–∫–µ Swift, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç ...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.0004027303075417876, 'severe_to...</td>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1'], 'count': [1]}</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9685d79e-16d7-4f1b-b68f-a1ff73e87bef</td>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>97894afc-2204-4c7b-9b91-f1c71c10f032</td>\n",
       "      <td>2023-02-09T21:25:39.116134+00:00</td>\n",
       "      <td>func sortAndPrintArray(array: [Int]) {\\n    le...</td>\n",
       "      <td>assistant</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.0003712645557243377, 'severe_to...</td>\n",
       "      <td>68489e5c-978f-4ad7-a849-39a741fb5ae7</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['-1', '_skip_labeling'], 'count': [1...</td>\n",
       "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afee0474-c84a-4ae2-a9c9-8d575256312e</td>\n",
       "      <td>None</td>\n",
       "      <td>0a8f6864-6cda-4cf5-bc07-346470d6d493</td>\n",
       "      <td>2023-02-07T00:54:42.098108+00:00</td>\n",
       "      <td>Inventa un monstruo altamente complejo, descr√≠...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>es</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'toxicity': 0.029511522501707077, 'severe_tox...</td>\n",
       "      <td>afee0474-c84a-4ae2-a9c9-8d575256312e</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>{'name': ['+1', '-1', '_skip_reply'], 'count':...</td>\n",
       "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             message_id                             parent_id   \n",
       "0  68489e5c-978f-4ad7-a849-39a741fb5ae7                                  None  \\\n",
       "1  a38b3d1c-256f-47c5-ab68-c9ab766bad84  68489e5c-978f-4ad7-a849-39a741fb5ae7   \n",
       "2  9cf52b01-0582-46aa-9ad2-70827dce87ed  68489e5c-978f-4ad7-a849-39a741fb5ae7   \n",
       "3  9685d79e-16d7-4f1b-b68f-a1ff73e87bef  68489e5c-978f-4ad7-a849-39a741fb5ae7   \n",
       "4  afee0474-c84a-4ae2-a9c9-8d575256312e                                  None   \n",
       "\n",
       "                                user_id                      created_date   \n",
       "0  845cba79-9d16-4eb8-ab63-982fe8403c62  2023-02-08T11:55:51.852473+00:00  \\\n",
       "1  abbc8a37-2db7-4af5-9df1-b0582d2e3d93  2023-03-16T22:29:28.829265+00:00   \n",
       "2  a3e19dd4-34cd-48f0-8912-a2003b22c334  2023-02-11T09:57:39.207727+00:00   \n",
       "3  97894afc-2204-4c7b-9b91-f1c71c10f032  2023-02-09T21:25:39.116134+00:00   \n",
       "4  0a8f6864-6cda-4cf5-bc07-346470d6d493  2023-02-07T00:54:42.098108+00:00   \n",
       "\n",
       "                                                text       role lang   \n",
       "0  –ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —è–∑—ã–∫–µ swift, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É...   prompter   ru  \\\n",
       "1  –í–æ—Ç —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–∞—Å—Å–∏–≤ —Ü–µ–ª—ã—Ö —á–∏...  assistant   ru   \n",
       "2  –í–æ—Ç —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞ —è–∑—ã–∫–µ Swift, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç ...  assistant   ru   \n",
       "3  func sortAndPrintArray(array: [Int]) {\\n    le...  assistant   ru   \n",
       "4  Inventa un monstruo altamente complejo, descr√≠...   prompter   es   \n",
       "\n",
       "   review_count review_result  deleted  rank  synthetic model_name   \n",
       "0             3          True    False   NaN      False       None  \\\n",
       "1             3          True    False   0.0      False       None   \n",
       "2             3          True    False   1.0      False       None   \n",
       "3             3          True    False   2.0      False       None   \n",
       "4             3          True    False   NaN      False       None   \n",
       "\n",
       "                                            detoxify   \n",
       "0  {'toxicity': 0.0025964330416172743, 'severe_to...  \\\n",
       "1  {'toxicity': 0.0003634887107182294, 'severe_to...   \n",
       "2  {'toxicity': 0.0004027303075417876, 'severe_to...   \n",
       "3  {'toxicity': 0.0003712645557243377, 'severe_to...   \n",
       "4  {'toxicity': 0.029511522501707077, 'severe_tox...   \n",
       "\n",
       "                        message_tree_id        tree_state   \n",
       "0  68489e5c-978f-4ad7-a849-39a741fb5ae7  ready_for_export  \\\n",
       "1  68489e5c-978f-4ad7-a849-39a741fb5ae7  ready_for_export   \n",
       "2  68489e5c-978f-4ad7-a849-39a741fb5ae7  ready_for_export   \n",
       "3  68489e5c-978f-4ad7-a849-39a741fb5ae7  ready_for_export   \n",
       "4  afee0474-c84a-4ae2-a9c9-8d575256312e  ready_for_export   \n",
       "\n",
       "                                              emojis   \n",
       "0  {'name': ['+1', '_skip_reply', '_skip_ranking'...  \\\n",
       "1  {'name': ['+1', '_skip_labeling'], 'count': [1...   \n",
       "2                     {'name': ['+1'], 'count': [1]}   \n",
       "3  {'name': ['-1', '_skip_labeling'], 'count': [1...   \n",
       "4  {'name': ['+1', '-1', '_skip_reply'], 'count':...   \n",
       "\n",
       "                                              labels  \n",
       "0  {'name': ['spam', 'lang_mismatch', 'pii', 'not...  \n",
       "1  {'name': ['spam', 'fails_task', 'lang_mismatch...  \n",
       "2  {'name': ['spam', 'fails_task', 'lang_mismatch...  \n",
       "3  {'name': ['spam', 'fails_task', 'lang_mismatch...  \n",
       "4  {'name': ['spam', 'lang_mismatch', 'pii', 'not...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oasst1_validation = pd.DataFrame(dataset_oasst1[\"validation\"])\n",
    "df_oasst1_validation = df_oasst1_validation.loc[df_oasst1_validation[\"review_result\"].fillna(False)]\n",
    "df_oasst1_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you write a short introduction about the r...</td>\n",
       "      <td>prompter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Monopsony\" refers to a market structure where...</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now explain it to a dog</td>\n",
       "      <td>prompter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       role\n",
       "0  Can you write a short introduction about the r...   prompter\n",
       "1  \"Monopsony\" refers to a market structure where...  assistant\n",
       "2                            Now explain it to a dog   prompter"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oasst1_indices_train, df_oasst1_texts_train = oasst1_2_messages(df_oasst1_train)\n",
    "df_oasst1_texts_train.loc[oasst1_indices_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —è–∑—ã–∫–µ swift, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É...</td>\n",
       "      <td>prompter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–í–æ—Ç —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–∞—Å—Å–∏–≤ —Ü–µ–ª—ã—Ö —á–∏...</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       role\n",
       "0  –ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —è–∑—ã–∫–µ swift, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É...   prompter\n",
       "1  –í–æ—Ç —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–∞—Å—Å–∏–≤ —Ü–µ–ª—ã—Ö —á–∏...  assistant"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oasst1_indices_validation, df_oasst1_texts_validation = oasst1_2_messages(df_oasst1_validation)\n",
    "df_oasst1_texts_validation.loc[oasst1_indices_validation[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–æ—Ç —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–∞—Å—Å–∏–≤ —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª –∏ –≤—ã–≤–æ–¥–∏—Ç –µ–≥–æ –Ω–∞ —ç–∫—Ä–∞–Ω:\n",
      "\n",
      "```swift\n",
      "func sortAndPrintArray(_ array: [Int]) {\n",
      "  // –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –º–∞—Å—Å–∏–≤–∞, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π\n",
      "  var sortedArray = array\n",
      "  // –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–∞—Å—Å–∏–≤ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é\n",
      "  sortedArray.sort()\n",
      "  // –í—ã–≤–æ–¥–∏–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ –Ω–∞ —ç–∫—Ä–∞–Ω\n",
      "  print(sortedArray)\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "–¢—ã –º–æ–∂–µ—à—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É —Ñ—É–Ω–∫—Ü–∏–∏, –≤—ã–∑–≤–∞–≤ –µ–µ —Å –ª—é–±—ã–º –º–∞—Å—Å–∏–≤–æ–º —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n",
      "\n",
      "```swift\n",
      "sortAndPrintArray([5, 2, 7, 9, -3])\n",
      "```\n",
      "\n",
      "–ù–∞ —ç–∫—Ä–∞–Ω–µ –ø–æ—è–≤–∏—Ç—Å—è:\n",
      "\n",
      "```sh\n",
      "[-3, 2, 5, 7, 9]\n",
      "```\n",
      "---\n",
      "–ù–∞–¥–µ—é—Å—å, —á—Ç–æ —è —Å–º–æ–≥ —Ç–µ–±–µ –ø–æ–º–æ—á—å. –ù—É–∂–Ω–æ –ª–∏ —Ç–µ–±–µ —á—Ç–æ-–Ω–∏–±—É–¥—å –µ—â—ë? üòä\n"
     ]
    }
   ],
   "source": [
    "print(df_oasst1_texts_validation.loc[oasst1_indices_validation[0]][\"text\"].values[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/alex4321/.cache/huggingface/datasets/tatsu-lab___parquet/tatsu-lab--alpaca-2b32f0433506ef5f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td></td>\n",
       "      <td>1.Eat a balanced diet and make sure to include...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the three primary colors?</td>\n",
       "      <td></td>\n",
       "      <td>The three primary colors are red, blue, and ye...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe the structure of an atom.</td>\n",
       "      <td></td>\n",
       "      <td>An atom is made up of a nucleus, which contain...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can we reduce air pollution?</td>\n",
       "      <td></td>\n",
       "      <td>There are a number of ways to reduce air pollu...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Describe a time when you had to make a difficu...</td>\n",
       "      <td></td>\n",
       "      <td>I had to make a difficult decision when I was ...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction input   \n",
       "0               Give three tips for staying healthy.        \\\n",
       "1                 What are the three primary colors?         \n",
       "2                 Describe the structure of an atom.         \n",
       "3                   How can we reduce air pollution?         \n",
       "4  Describe a time when you had to make a difficu...         \n",
       "\n",
       "                                              output   \n",
       "0  1.Eat a balanced diet and make sure to include...  \\\n",
       "1  The three primary colors are red, blue, and ye...   \n",
       "2  An atom is made up of a nucleus, which contain...   \n",
       "3  There are a number of ways to reduce air pollu...   \n",
       "4  I had to make a difficult decision when I was ...   \n",
       "\n",
       "                                                text  \n",
       "0  Below is an instruction that describes a task....  \n",
       "1  Below is an instruction that describes a task....  \n",
       "2  Below is an instruction that describes a task....  \n",
       "3  Below is an instruction that describes a task....  \n",
       "4  Below is an instruction that describes a task....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alpaca = pd.DataFrame(load_dataset(\"tatsu-lab/alpaca\")[\"train\"])\n",
    "df_alpaca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alpaca[\"input_message\"] = df_alpaca.apply(\n",
    "    lambda row: f\"Below is an instruction that describes a task, paired with an input that provides further context. \" + \\\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\" + \\\n",
    "        \"### Instruction:\\n\" + \\\n",
    "        f\"{row['instruction']}\\n\" + \\\n",
    "        \"\\n\" + \\\n",
    "        \"### Input:\\n\" +\n",
    "        f\"{row['input']}\",\n",
    "    axis=1\n",
    ")\n",
    "df_alpaca[\"output_message\"] = df_alpaca[\"output\"]\n",
    "df_alpaca = df_alpaca[[\"input_message\", \"output_message\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alpaca_texts = []\n",
    "alpaca_indices = []\n",
    "for _, row in df_alpaca.iterrows():\n",
    "    df_alpaca_texts.append({\"role\": \"prompter\", \"text\": row[\"input_message\"]})\n",
    "    df_alpaca_texts.append({\"role\": \"assistant\", \"text\": row[\"output_message\"]})\n",
    "    alpaca_indices.append([len(df_alpaca_texts) - 2, len(df_alpaca_texts) - 1])\n",
    "df_alpaca_texts = pd.DataFrame.from_records(df_alpaca_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_indices_train, alpaca_indices_validation = train_test_split(\n",
    "    alpaca_indices,\n",
    "    random_state=RANDOM_STATE,\n",
    "    test_size=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52562</th>\n",
       "      <td>prompter</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52563</th>\n",
       "      <td>assistant</td>\n",
       "      <td>The sound of the alarm was really irritating.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            role                                               text\n",
       "52562   prompter  Below is an instruction that describes a task,...\n",
       "52563  assistant      The sound of the alarm was really irritating."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alpaca_texts.loc[alpaca_indices_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67832</th>\n",
       "      <td>prompter</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67833</th>\n",
       "      <td>assistant</td>\n",
       "      <td>#ReduceToSucceed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            role                                               text\n",
       "67832   prompter  Below is an instruction that describes a task,...\n",
       "67833  assistant                                   #ReduceToSucceed"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alpaca_texts.loc[alpaca_indices_train[1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/alex4321/.cache/huggingface/datasets/nomic-ai___parquet/nomic-ai--gpt4all_prompt_generations-94ada251779e8693/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I installed Cassandra and Spark with SparkS...</td>\n",
       "      <td>It seems that the error is caused by the synta...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;I have an mnesia table with fields say f1, ...</td>\n",
       "      <td>You can use a match specification in mnesia to...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;I have a form with an input of type field. ...</td>\n",
       "      <td>As an AI language model, I cannot guarantee th...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Is there a way to change how fast the toolt...</td>\n",
       "      <td>As an AI language model, I don't have personal...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;I have configured the data source and set a...</td>\n",
       "      <td>One potential issue with the code is that the ...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt   \n",
       "0  <p>I installed Cassandra and Spark with SparkS...  \\\n",
       "1  <p>I have an mnesia table with fields say f1, ...   \n",
       "2  <p>I have a form with an input of type field. ...   \n",
       "3  <p>Is there a way to change how fast the toolt...   \n",
       "4  <p>I have configured the data source and set a...   \n",
       "\n",
       "                                            response   \n",
       "0  It seems that the error is caused by the synta...  \\\n",
       "1  You can use a match specification in mnesia to...   \n",
       "2  As an AI language model, I cannot guarantee th...   \n",
       "3  As an AI language model, I don't have personal...   \n",
       "4  One potential issue with the code is that the ...   \n",
       "\n",
       "                               source  \n",
       "0  pacovaldez/stackoverflow-questions  \n",
       "1  pacovaldez/stackoverflow-questions  \n",
       "2  pacovaldez/stackoverflow-questions  \n",
       "3  pacovaldez/stackoverflow-questions  \n",
       "4  pacovaldez/stackoverflow-questions  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4all = pd.DataFrame(load_dataset(\"nomic-ai/gpt4all_prompt_generations\")[\"train\"])\n",
    "df_gpt4all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I installed Cassandra and Spark with SparkS...</td>\n",
       "      <td>It seems that the error is caused by the synta...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;I have an mnesia table with fields say f1, ...</td>\n",
       "      <td>You can use a match specification in mnesia to...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;I have configured the data source and set a...</td>\n",
       "      <td>One potential issue with the code is that the ...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p&gt;I've installed Java 8 for development purpo...</td>\n",
       "      <td>To switch back to Java 7 from Java 8, you need...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;p&gt;This code is an attempt to bind a command t...</td>\n",
       "      <td>The code above does not work because the \"Esca...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt   \n",
       "0  <p>I installed Cassandra and Spark with SparkS...  \\\n",
       "1  <p>I have an mnesia table with fields say f1, ...   \n",
       "4  <p>I have configured the data source and set a...   \n",
       "5  <p>I've installed Java 8 for development purpo...   \n",
       "6  <p>This code is an attempt to bind a command t...   \n",
       "\n",
       "                                            response   \n",
       "0  It seems that the error is caused by the synta...  \\\n",
       "1  You can use a match specification in mnesia to...   \n",
       "4  One potential issue with the code is that the ...   \n",
       "5  To switch back to Java 7 from Java 8, you need...   \n",
       "6  The code above does not work because the \"Esca...   \n",
       "\n",
       "                               source  \n",
       "0  pacovaldez/stackoverflow-questions  \n",
       "1  pacovaldez/stackoverflow-questions  \n",
       "4  pacovaldez/stackoverflow-questions  \n",
       "5  pacovaldez/stackoverflow-questions  \n",
       "6  pacovaldez/stackoverflow-questions  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4all = df_gpt4all.loc[~df_gpt4all[\"response\"].str.contains(\"As an AI language\")]\n",
    "df_gpt4all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _markdownify_if_possible(text):\n",
    "    try:\n",
    "        return markdownify(text)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex4321/anaconda3/envs/longdocchat/lib/python3.11/site-packages/markdownify/__init__.py:96: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, 'html.parser')\n",
      "/home/alex4321/anaconda3/envs/longdocchat/lib/python3.11/site-packages/markdownify/__init__.py:96: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, 'html.parser')\n",
      "/home/alex4321/anaconda3/envs/longdocchat/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_markdown</th>\n",
       "      <th>response_markdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I installed Cassandra and Spark with SparkS...</td>\n",
       "      <td>It seems that the error is caused by the synta...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "      <td>I installed Cassandra and Spark with SparkSQL ...</td>\n",
       "      <td>It seems that the error is caused by the synta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;I have an mnesia table with fields say f1, ...</td>\n",
       "      <td>You can use a match specification in mnesia to...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "      <td>I have an mnesia table with fields say f1, f2,...</td>\n",
       "      <td>You can use a match specification in mnesia to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;I have configured the data source and set a...</td>\n",
       "      <td>One potential issue with the code is that the ...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "      <td>I have configured the data source and set auto...</td>\n",
       "      <td>One potential issue with the code is that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p&gt;I've installed Java 8 for development purpo...</td>\n",
       "      <td>To switch back to Java 7 from Java 8, you need...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "      <td>I've installed Java 8 for development purposes...</td>\n",
       "      <td>To switch back to Java 7 from Java 8, you need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;p&gt;This code is an attempt to bind a command t...</td>\n",
       "      <td>The code above does not work because the \"Esca...</td>\n",
       "      <td>pacovaldez/stackoverflow-questions</td>\n",
       "      <td>This code is an attempt to bind a command to a...</td>\n",
       "      <td>The code above does not work because the \"Esca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt   \n",
       "0  <p>I installed Cassandra and Spark with SparkS...  \\\n",
       "1  <p>I have an mnesia table with fields say f1, ...   \n",
       "4  <p>I have configured the data source and set a...   \n",
       "5  <p>I've installed Java 8 for development purpo...   \n",
       "6  <p>This code is an attempt to bind a command t...   \n",
       "\n",
       "                                            response   \n",
       "0  It seems that the error is caused by the synta...  \\\n",
       "1  You can use a match specification in mnesia to...   \n",
       "4  One potential issue with the code is that the ...   \n",
       "5  To switch back to Java 7 from Java 8, you need...   \n",
       "6  The code above does not work because the \"Esca...   \n",
       "\n",
       "                               source   \n",
       "0  pacovaldez/stackoverflow-questions  \\\n",
       "1  pacovaldez/stackoverflow-questions   \n",
       "4  pacovaldez/stackoverflow-questions   \n",
       "5  pacovaldez/stackoverflow-questions   \n",
       "6  pacovaldez/stackoverflow-questions   \n",
       "\n",
       "                                     prompt_markdown   \n",
       "0  I installed Cassandra and Spark with SparkSQL ...  \\\n",
       "1  I have an mnesia table with fields say f1, f2,...   \n",
       "4  I have configured the data source and set auto...   \n",
       "5  I've installed Java 8 for development purposes...   \n",
       "6  This code is an attempt to bind a command to a...   \n",
       "\n",
       "                                   response_markdown  \n",
       "0  It seems that the error is caused by the synta...  \n",
       "1  You can use a match specification in mnesia to...  \n",
       "4  One potential issue with the code is that the ...  \n",
       "5  To switch back to Java 7 from Java 8, you need...  \n",
       "6  The code above does not work because the \"Esca...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4all[\"prompt_markdown\"] = df_gpt4all[\"prompt\"].apply(_markdownify_if_possible)\n",
    "df_gpt4all[\"response_markdown\"] = df_gpt4all[\"response\"].apply(_markdownify_if_possible)\n",
    "df_gpt4all = df_gpt4all.loc[df_gpt4all[\"prompt_markdown\"].apply(bool) & df_gpt4all[\"response_markdown\"].apply(bool)]\n",
    "df_gpt4all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4all_texts = []\n",
    "gpt4_all_indices = []\n",
    "for _, row in df_gpt4all.iterrows():\n",
    "    df_gpt4all_texts.append({\"role\": \"prompter\", \"text\": row[\"prompt_markdown\"]})\n",
    "    df_gpt4all_texts.append({\"role\": \"assistant\", \"text\": row[\"response_markdown\"]})\n",
    "    gpt4_all_indices.append([len(df_gpt4all_texts) - 2, len(df_gpt4all_texts) - 1])\n",
    "df_gpt4all_texts = pd.DataFrame.from_records(df_gpt4all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4all_indices_train, gpt4all_indices_validation = train_test_split(\n",
    "    gpt4_all_indices,\n",
    "    random_state=RANDOM_STATE,\n",
    "    test_size=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>635152</th>\n",
       "      <td>prompter</td>\n",
       "      <td>I have tried all the possible solutions availa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635153</th>\n",
       "      <td>assistant</td>\n",
       "      <td>The error is occurring because the URL you hav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             role                                               text\n",
       "635152   prompter  I have tried all the possible solutions availa...\n",
       "635153  assistant  The error is occurring because the URL you hav..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4all_texts.loc[gpt4all_indices_train[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BookSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/alex4321/.cache/huggingface/datasets/kmfoda___csv/kmfoda--booksum-025141c210e07407/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 34.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
       "        num_rows: 1484\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['bid', 'is_aggregate', 'source', 'chapter_path', 'summary_path', 'book_id', 'summary_id', 'content', 'summary', 'chapter', 'chapter_length', 'summary_name', 'summary_url', 'summary_text', 'summary_analysis', 'summary_length', 'analysis_length'],\n",
       "        num_rows: 1431\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_booksum = load_dataset(\"kmfoda/booksum\")\n",
    "dataset_booksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid</th>\n",
       "      <th>is_aggregate</th>\n",
       "      <th>source</th>\n",
       "      <th>chapter_path</th>\n",
       "      <th>summary_path</th>\n",
       "      <th>book_id</th>\n",
       "      <th>summary_id</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "      <th>chapter</th>\n",
       "      <th>chapter_length</th>\n",
       "      <th>summary_name</th>\n",
       "      <th>summary_url</th>\n",
       "      <th>summary_text</th>\n",
       "      <th>summary_analysis</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>analysis_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27681</td>\n",
       "      <td>True</td>\n",
       "      <td>cliffnotes</td>\n",
       "      <td>all_chapterized_books/27681-chapters/chapters_...</td>\n",
       "      <td>finished_summaries/cliffnotes/The Last of the ...</td>\n",
       "      <td>The Last of the Mohicans.chapters 1-2</td>\n",
       "      <td>chapters 1-2</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapters 1-2\", \"url\": \"https://web.a...</td>\n",
       "      <td>\\n  \"Mine ear is open, and my heart prepared:\\...</td>\n",
       "      <td>6471.0</td>\n",
       "      <td>Chapters 1-2</td>\n",
       "      <td>https://web.archive.org/web/20201101053205/htt...</td>\n",
       "      <td>Before any characters appear, the time and geo...</td>\n",
       "      <td>These two chapters introduce the reader to the...</td>\n",
       "      <td>388.0</td>\n",
       "      <td>473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27681</td>\n",
       "      <td>False</td>\n",
       "      <td>cliffnotes</td>\n",
       "      <td>all_chapterized_books/27681-chapters/03.txt</td>\n",
       "      <td>finished_summaries/cliffnotes/The Last of the ...</td>\n",
       "      <td>The Last of the Mohicans.chapter 3</td>\n",
       "      <td>chapter 3</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapter 3\", \"url\": \"https://web.arch...</td>\n",
       "      <td>\\n  \"Before these fields were shorn and tilled...</td>\n",
       "      <td>3132.0</td>\n",
       "      <td>Chapter 3</td>\n",
       "      <td>https://web.archive.org/web/20201101053205/htt...</td>\n",
       "      <td>In another part of the forest by the river a f...</td>\n",
       "      <td>This chapter introduces the other three main a...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27681</td>\n",
       "      <td>False</td>\n",
       "      <td>cliffnotes</td>\n",
       "      <td>all_chapterized_books/27681-chapters/04.txt</td>\n",
       "      <td>finished_summaries/cliffnotes/The Last of the ...</td>\n",
       "      <td>The Last of the Mohicans.chapter 4</td>\n",
       "      <td>chapter 4</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapter 4\", \"url\": \"https://web.arch...</td>\n",
       "      <td>\\n  \"Well, go thy way: thou shalt not from thi...</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>Chapter 4</td>\n",
       "      <td>https://web.archive.org/web/20201101053205/htt...</td>\n",
       "      <td>When the mounted party from Fort Howard approa...</td>\n",
       "      <td>Since this chapter is mostly one of surface ac...</td>\n",
       "      <td>319.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27681</td>\n",
       "      <td>False</td>\n",
       "      <td>cliffnotes</td>\n",
       "      <td>all_chapterized_books/27681-chapters/05.txt</td>\n",
       "      <td>finished_summaries/cliffnotes/The Last of the ...</td>\n",
       "      <td>The Last of the Mohicans.chapter 5</td>\n",
       "      <td>chapter 5</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapter 5\", \"url\": \"https://web.arch...</td>\n",
       "      <td>\\n                      \"In such a night\\n  Di...</td>\n",
       "      <td>3268.0</td>\n",
       "      <td>Chapter 5</td>\n",
       "      <td>https://web.archive.org/web/20201101053205/htt...</td>\n",
       "      <td>The pursuit of Magua is unsuccessful, but Hawk...</td>\n",
       "      <td>Here the reader encounters the first bloodshed...</td>\n",
       "      <td>329.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27681</td>\n",
       "      <td>False</td>\n",
       "      <td>cliffnotes</td>\n",
       "      <td>all_chapterized_books/27681-chapters/06.txt</td>\n",
       "      <td>finished_summaries/cliffnotes/The Last of the ...</td>\n",
       "      <td>The Last of the Mohicans.chapter 6</td>\n",
       "      <td>chapter 6</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapter 6\", \"url\": \"https://web.arch...</td>\n",
       "      <td>\\n  \"Those strains that once did sweet in Zion...</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>Chapter 6</td>\n",
       "      <td>https://web.archive.org/web/20201101053205/htt...</td>\n",
       "      <td>Heyward and the girls are uneasy and Gamut is ...</td>\n",
       "      <td>This chapter shows Cooper in his most inventiv...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bid  is_aggregate      source   \n",
       "0  27681          True  cliffnotes  \\\n",
       "1  27681         False  cliffnotes   \n",
       "2  27681         False  cliffnotes   \n",
       "3  27681         False  cliffnotes   \n",
       "4  27681         False  cliffnotes   \n",
       "\n",
       "                                        chapter_path   \n",
       "0  all_chapterized_books/27681-chapters/chapters_...  \\\n",
       "1        all_chapterized_books/27681-chapters/03.txt   \n",
       "2        all_chapterized_books/27681-chapters/04.txt   \n",
       "3        all_chapterized_books/27681-chapters/05.txt   \n",
       "4        all_chapterized_books/27681-chapters/06.txt   \n",
       "\n",
       "                                        summary_path   \n",
       "0  finished_summaries/cliffnotes/The Last of the ...  \\\n",
       "1  finished_summaries/cliffnotes/The Last of the ...   \n",
       "2  finished_summaries/cliffnotes/The Last of the ...   \n",
       "3  finished_summaries/cliffnotes/The Last of the ...   \n",
       "4  finished_summaries/cliffnotes/The Last of the ...   \n",
       "\n",
       "                                 book_id    summary_id content   \n",
       "0  The Last of the Mohicans.chapters 1-2  chapters 1-2    None  \\\n",
       "1     The Last of the Mohicans.chapter 3     chapter 3    None   \n",
       "2     The Last of the Mohicans.chapter 4     chapter 4    None   \n",
       "3     The Last of the Mohicans.chapter 5     chapter 5    None   \n",
       "4     The Last of the Mohicans.chapter 6     chapter 6    None   \n",
       "\n",
       "                                             summary   \n",
       "0  {\"name\": \"Chapters 1-2\", \"url\": \"https://web.a...  \\\n",
       "1  {\"name\": \"Chapter 3\", \"url\": \"https://web.arch...   \n",
       "2  {\"name\": \"Chapter 4\", \"url\": \"https://web.arch...   \n",
       "3  {\"name\": \"Chapter 5\", \"url\": \"https://web.arch...   \n",
       "4  {\"name\": \"Chapter 6\", \"url\": \"https://web.arch...   \n",
       "\n",
       "                                             chapter  chapter_length   \n",
       "0  \\n  \"Mine ear is open, and my heart prepared:\\...          6471.0  \\\n",
       "1  \\n  \"Before these fields were shorn and tilled...          3132.0   \n",
       "2  \\n  \"Well, go thy way: thou shalt not from thi...          3075.0   \n",
       "3  \\n                      \"In such a night\\n  Di...          3268.0   \n",
       "4  \\n  \"Those strains that once did sweet in Zion...          3873.0   \n",
       "\n",
       "   summary_name                                        summary_url   \n",
       "0  Chapters 1-2  https://web.archive.org/web/20201101053205/htt...  \\\n",
       "1     Chapter 3  https://web.archive.org/web/20201101053205/htt...   \n",
       "2     Chapter 4  https://web.archive.org/web/20201101053205/htt...   \n",
       "3     Chapter 5  https://web.archive.org/web/20201101053205/htt...   \n",
       "4     Chapter 6  https://web.archive.org/web/20201101053205/htt...   \n",
       "\n",
       "                                        summary_text   \n",
       "0  Before any characters appear, the time and geo...  \\\n",
       "1  In another part of the forest by the river a f...   \n",
       "2  When the mounted party from Fort Howard approa...   \n",
       "3  The pursuit of Magua is unsuccessful, but Hawk...   \n",
       "4  Heyward and the girls are uneasy and Gamut is ...   \n",
       "\n",
       "                                    summary_analysis  summary_length   \n",
       "0  These two chapters introduce the reader to the...           388.0  \\\n",
       "1  This chapter introduces the other three main a...           198.0   \n",
       "2  Since this chapter is mostly one of surface ac...           319.0   \n",
       "3  Here the reader encounters the first bloodshed...           329.0   \n",
       "4  This chapter shows Cooper in his most inventiv...           321.0   \n",
       "\n",
       "   analysis_length  \n",
       "0            473.0  \n",
       "1            149.0  \n",
       "2             75.0  \n",
       "3            156.0  \n",
       "4            128.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booksum_train = pd.concat([pd.DataFrame(dataset_booksum[\"train\"]), pd.DataFrame(dataset_booksum[\"test\"])]).reset_index(drop=True)\n",
    "df_booksum_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid</th>\n",
       "      <th>is_aggregate</th>\n",
       "      <th>source</th>\n",
       "      <th>chapter_path</th>\n",
       "      <th>summary_path</th>\n",
       "      <th>book_id</th>\n",
       "      <th>summary_id</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "      <th>chapter</th>\n",
       "      <th>chapter_length</th>\n",
       "      <th>summary_name</th>\n",
       "      <th>summary_url</th>\n",
       "      <th>summary_text</th>\n",
       "      <th>summary_analysis</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>analysis_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023</td>\n",
       "      <td>True</td>\n",
       "      <td>gradesaver</td>\n",
       "      <td>all_chapterized_books/1023-chapters/chapters_1...</td>\n",
       "      <td>finished_summaries/gradesaver/Bleak House/sect...</td>\n",
       "      <td>Bleak House.chapters 1-4</td>\n",
       "      <td>chapters 1-4</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapters 1-4\", \"url\": \"https://web.a...</td>\n",
       "      <td>London. Michaelmas term lately over, and the L...</td>\n",
       "      <td>16554.0</td>\n",
       "      <td>Chapters 1-4</td>\n",
       "      <td>https://web.archive.org/web/20210421025427/htt...</td>\n",
       "      <td>The scene opens in London on a foggy, smoggy d...</td>\n",
       "      <td>Dickens immediately plunges the readers in med...</td>\n",
       "      <td>635.0</td>\n",
       "      <td>536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1023</td>\n",
       "      <td>True</td>\n",
       "      <td>gradesaver</td>\n",
       "      <td>all_chapterized_books/1023-chapters/chapters_5...</td>\n",
       "      <td>finished_summaries/gradesaver/Bleak House/sect...</td>\n",
       "      <td>Bleak House.chapters 5-7</td>\n",
       "      <td>chapters 5-7</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapters 5-7\", \"url\": \"https://web.a...</td>\n",
       "      <td>Although the morning was raw, and although the...</td>\n",
       "      <td>16887.0</td>\n",
       "      <td>Chapters 5-7</td>\n",
       "      <td>https://web.archive.org/web/20210421025427/htt...</td>\n",
       "      <td>Caddy Jellyby has spent the night in Esther an...</td>\n",
       "      <td>The coincidence of Esther arriving at the home...</td>\n",
       "      <td>635.0</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023</td>\n",
       "      <td>True</td>\n",
       "      <td>gradesaver</td>\n",
       "      <td>all_chapterized_books/1023-chapters/chapters_8...</td>\n",
       "      <td>finished_summaries/gradesaver/Bleak House/sect...</td>\n",
       "      <td>Bleak House.chapters 8-10</td>\n",
       "      <td>chapters 8-10</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapters 8-10\", \"url\": \"https://web....</td>\n",
       "      <td>It was interesting when I dressed before dayli...</td>\n",
       "      <td>17028.0</td>\n",
       "      <td>Chapters 8-10</td>\n",
       "      <td>https://web.archive.org/web/20210421025427/htt...</td>\n",
       "      <td>Esther and Mr. Jarndyce discuss the Chancery s...</td>\n",
       "      <td>We find Esther settled comfortably at Bleak Ho...</td>\n",
       "      <td>609.0</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023</td>\n",
       "      <td>True</td>\n",
       "      <td>gradesaver</td>\n",
       "      <td>all_chapterized_books/1023-chapters/chapters_1...</td>\n",
       "      <td>finished_summaries/gradesaver/Bleak House/sect...</td>\n",
       "      <td>Bleak House.chapters 11-13</td>\n",
       "      <td>chapters 11-13</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapters 11-13\", \"url\": \"https://web...</td>\n",
       "      <td>A touch on the lawyer's wrinkled hand as he st...</td>\n",
       "      <td>15739.0</td>\n",
       "      <td>Chapters 11-13</td>\n",
       "      <td>https://web.archive.org/web/20210421025427/htt...</td>\n",
       "      <td>Tulkinghorn and Krook find Nemo dead, apparent...</td>\n",
       "      <td>Nemo's death, so eerie and sordid, leaves the ...</td>\n",
       "      <td>484.0</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023</td>\n",
       "      <td>True</td>\n",
       "      <td>gradesaver</td>\n",
       "      <td>all_chapterized_books/1023-chapters/chapters_1...</td>\n",
       "      <td>finished_summaries/gradesaver/Bleak House/sect...</td>\n",
       "      <td>Bleak House.chapters 14-16</td>\n",
       "      <td>chapters 14-16</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"name\": \"Chapters 14-16\", \"url\": \"https://web...</td>\n",
       "      <td>Richard left us on the very next evening to be...</td>\n",
       "      <td>16636.0</td>\n",
       "      <td>Chapters 14-16</td>\n",
       "      <td>https://web.archive.org/web/20210421025427/htt...</td>\n",
       "      <td>Richard leaves to start his studies. He is hop...</td>\n",
       "      <td>Again, Dickens treats the dissarray of badly p...</td>\n",
       "      <td>546.0</td>\n",
       "      <td>436.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bid  is_aggregate      source   \n",
       "0  1023          True  gradesaver  \\\n",
       "1  1023          True  gradesaver   \n",
       "2  1023          True  gradesaver   \n",
       "3  1023          True  gradesaver   \n",
       "4  1023          True  gradesaver   \n",
       "\n",
       "                                        chapter_path   \n",
       "0  all_chapterized_books/1023-chapters/chapters_1...  \\\n",
       "1  all_chapterized_books/1023-chapters/chapters_5...   \n",
       "2  all_chapterized_books/1023-chapters/chapters_8...   \n",
       "3  all_chapterized_books/1023-chapters/chapters_1...   \n",
       "4  all_chapterized_books/1023-chapters/chapters_1...   \n",
       "\n",
       "                                        summary_path   \n",
       "0  finished_summaries/gradesaver/Bleak House/sect...  \\\n",
       "1  finished_summaries/gradesaver/Bleak House/sect...   \n",
       "2  finished_summaries/gradesaver/Bleak House/sect...   \n",
       "3  finished_summaries/gradesaver/Bleak House/sect...   \n",
       "4  finished_summaries/gradesaver/Bleak House/sect...   \n",
       "\n",
       "                      book_id      summary_id content   \n",
       "0    Bleak House.chapters 1-4    chapters 1-4    None  \\\n",
       "1    Bleak House.chapters 5-7    chapters 5-7    None   \n",
       "2   Bleak House.chapters 8-10   chapters 8-10    None   \n",
       "3  Bleak House.chapters 11-13  chapters 11-13    None   \n",
       "4  Bleak House.chapters 14-16  chapters 14-16    None   \n",
       "\n",
       "                                             summary   \n",
       "0  {\"name\": \"Chapters 1-4\", \"url\": \"https://web.a...  \\\n",
       "1  {\"name\": \"Chapters 5-7\", \"url\": \"https://web.a...   \n",
       "2  {\"name\": \"Chapters 8-10\", \"url\": \"https://web....   \n",
       "3  {\"name\": \"Chapters 11-13\", \"url\": \"https://web...   \n",
       "4  {\"name\": \"Chapters 14-16\", \"url\": \"https://web...   \n",
       "\n",
       "                                             chapter  chapter_length   \n",
       "0  London. Michaelmas term lately over, and the L...         16554.0  \\\n",
       "1  Although the morning was raw, and although the...         16887.0   \n",
       "2  It was interesting when I dressed before dayli...         17028.0   \n",
       "3  A touch on the lawyer's wrinkled hand as he st...         15739.0   \n",
       "4  Richard left us on the very next evening to be...         16636.0   \n",
       "\n",
       "     summary_name                                        summary_url   \n",
       "0    Chapters 1-4  https://web.archive.org/web/20210421025427/htt...  \\\n",
       "1    Chapters 5-7  https://web.archive.org/web/20210421025427/htt...   \n",
       "2   Chapters 8-10  https://web.archive.org/web/20210421025427/htt...   \n",
       "3  Chapters 11-13  https://web.archive.org/web/20210421025427/htt...   \n",
       "4  Chapters 14-16  https://web.archive.org/web/20210421025427/htt...   \n",
       "\n",
       "                                        summary_text   \n",
       "0  The scene opens in London on a foggy, smoggy d...  \\\n",
       "1  Caddy Jellyby has spent the night in Esther an...   \n",
       "2  Esther and Mr. Jarndyce discuss the Chancery s...   \n",
       "3  Tulkinghorn and Krook find Nemo dead, apparent...   \n",
       "4  Richard leaves to start his studies. He is hop...   \n",
       "\n",
       "                                    summary_analysis  summary_length   \n",
       "0  Dickens immediately plunges the readers in med...           635.0  \\\n",
       "1  The coincidence of Esther arriving at the home...           635.0   \n",
       "2  We find Esther settled comfortably at Bleak Ho...           609.0   \n",
       "3  Nemo's death, so eerie and sordid, leaves the ...           484.0   \n",
       "4  Again, Dickens treats the dissarray of badly p...           546.0   \n",
       "\n",
       "   analysis_length  \n",
       "0            536.0  \n",
       "1            673.0  \n",
       "2            363.0  \n",
       "3            345.0  \n",
       "4            436.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booksum_validation = pd.DataFrame(dataset_booksum[\"validation\"])\n",
    "df_booksum_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def booksum_process(df):\n",
    "    result_df = []\n",
    "    result_indices = []\n",
    "    for _, row in df.iterrows():\n",
    "        chapter = row[\"chapter\"].strip()\n",
    "        summary = json.loads(row[\"summary\"])[\"summary\"].strip()\n",
    "        result_df.append({\n",
    "            \"role\": \"prompter\",\n",
    "            \"text\": f\"{chapter}\\n\\nGive me the summary of previous text\",\n",
    "        })\n",
    "        result_df.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"text\": summary,\n",
    "        })\n",
    "        result_indices.append([len(result_df) - 2, len(result_df) - 1])\n",
    "    return pd.DataFrame.from_records(result_df), result_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booksum_texts_train, booksum_indices_train = booksum_process(df_booksum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booksum_texts_validation, booksum_indices_validation = booksum_process(df_booksum_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prompter</td>\n",
       "      <td>\"Mine ear is open, and my heart prepared:\\n  T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistant</td>\n",
       "      <td>Before any characters appear, the time and geo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        role                                               text\n",
       "0   prompter  \"Mine ear is open, and my heart prepared:\\n  T...\n",
       "1  assistant  Before any characters appear, the time and geo..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booksum_texts_train.loc[booksum_indices_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11031"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(booksum_indices_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GovReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: govreport-summarization/document\n",
      "Found cached dataset govreport-summarization (/home/alex4321/.cache/huggingface/datasets/ccdv___govreport-summarization/document/1.0.0/57ca3042de9c40c218cc94084cbc80a99a161036134bfc88112c57d251443590)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 29.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 17517\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_govreport = load_dataset(\"ccdv/govreport-summarization\")\n",
    "dataset_govreport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_govreport_train = pd.concat([pd.DataFrame(dataset_govreport[\"train\"]), pd.DataFrame(dataset_govreport[\"test\"])]).reset_index(drop=True)\n",
    "df_govreport_validation = pd.DataFrame(dataset_govreport[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def govreport_process(df):\n",
    "    result_df = []\n",
    "    result_indices = []\n",
    "    for _, row in df.iterrows():\n",
    "        report = row[\"report\"].strip()\n",
    "        summary = row[\"summary\"].strip()\n",
    "        result_df.append({\n",
    "            \"role\": \"prompter\",\n",
    "            \"text\": f\"{report}\\n\\nGive me the summary of previous text\",\n",
    "        })\n",
    "        result_df.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"text\": summary,\n",
    "        })\n",
    "        result_indices.append([len(result_df) - 2, len(result_df) - 1])\n",
    "    return pd.DataFrame.from_records(result_df), result_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_govreport_texts_train, govreport_indices_train = govreport_process(df_govreport_train)\n",
    "df_govreport_texts_validation, govreport_indices_validation = govreport_process(df_govreport_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prompter</td>\n",
       "      <td>The structure of the armed forces is based on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistant</td>\n",
       "      <td>As the Department of Defense (DOD) has expande...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        role                                               text\n",
       "0   prompter  The structure of the armed forces is based on ...\n",
       "1  assistant  As the Department of Defense (DOD) has expande..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_govreport_texts_train.loc[govreport_indices_train[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QASper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset qasper (/home/alex4321/.cache/huggingface/datasets/allenai___qasper/qasper/0.3.0/2bfcd239e581ab83f9ab7b76a82e42c6bcf574a13246ae6cc5a6c357c35f96f9)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 179.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'abstract', 'full_text', 'qas', 'figures_and_tables'],\n",
       "        num_rows: 888\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'abstract', 'full_text', 'qas', 'figures_and_tables'],\n",
       "        num_rows: 281\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'abstract', 'full_text', 'qas', 'figures_and_tables'],\n",
       "        num_rows: 416\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_qasper = load_dataset(\"allenai/qasper\")\n",
    "dataset_qasper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _qasper_article_text(data):\n",
    "    section_texts = []\n",
    "    for section_name, section_paragraphs in zip(data['section_name'], data['paragraphs']):\n",
    "        if not section_name:\n",
    "            section_name = \"\"\n",
    "        section_name_levels = section_name.split(\" ::: \")\n",
    "        section_name_last = section_name_levels[-1]\n",
    "        if section_name:\n",
    "            section_name_prefix = \"#\" * len(section_name_levels)\n",
    "            title = f\"{section_name_prefix} {section_name_last}\"\n",
    "        else:\n",
    "            title = \"\"\n",
    "        section_content = \"\\n\\n\".join(section_paragraphs)\n",
    "        section_texts.append(f\"{title}\\n\\n{section_content}\")\n",
    "    return \"\\n\\n\".join(section_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _qasper_article_qa_pairs(full_text_data, qas_data):\n",
    "    article_text = _qasper_article_text(full_text_data)\n",
    "\n",
    "    question_texts = qas_data[\"question\"]\n",
    "    answers = qas_data[\"answers\"]\n",
    "    for question, question_answers in zip(question_texts, answers):\n",
    "        for answer in question_answers[\"answer\"]:\n",
    "            answer_evidence = answer[\"highlighted_evidence\"]\n",
    "            answer_text = answer[\"free_form_answer\"]\n",
    "            if answer_evidence:\n",
    "                answer_evidence_text = \"\\n\".join([f\"- {item}\" for item in answer_evidence])\n",
    "                answer_message_text = f\"{answer_evidence_text}\\n\\n{answer_text}\"\n",
    "            else:\n",
    "                answer_message_text = answer_text\n",
    "            yield article_text, f\"Keeping this in mind, answer the following question: {question}\", answer_message_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasper_qa_pairs(df):\n",
    "    texts = []\n",
    "    indices = []\n",
    "    for _, row in df.iterrows():\n",
    "        row_qa_texts = []\n",
    "        for article_text, question_text, answer in _qasper_article_qa_pairs(row[\"full_text\"], row[\"qas\"]):\n",
    "            row_qa_texts.append((question_text, answer))\n",
    "        \n",
    "        texts.append({\"role\": \"prompter\", \"text\": article_text})\n",
    "        index_article = len(texts) - 1\n",
    "        for question, answer in row_qa_texts:\n",
    "            texts.append({\"role\": \"prompter\", \"text\": question})\n",
    "            texts.append({\"role\": \"assistant\", \"text\": answer})\n",
    "            index_question = len(texts) - 2\n",
    "            index_answer = len(texts) - 1\n",
    "            indices.append([index_article, index_question, index_answer])\n",
    "    \n",
    "    return pd.DataFrame.from_records(texts), indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qasper_train = pd.concat([pd.DataFrame(dataset_qasper[\"train\"]), pd.DataFrame(dataset_qasper[\"test\"])]).reset_index(drop=True)\n",
    "df_qasper_validation = pd.DataFrame(dataset_qasper[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qasper_texts_train, qasper_indices_train = quasper_qa_pairs(df_qasper_train)\n",
    "df_qasper_texts_validation, qasper_indices_validation = quasper_qa_pairs(df_qasper_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prompter</td>\n",
       "      <td># Introduction\\n\\nAffective events BIBREF0 are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prompter</td>\n",
       "      <td>Keeping this in mind, answer the following que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assistant</td>\n",
       "      <td>- The seed lexicon consists of positive and ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        role                                               text\n",
       "0   prompter  # Introduction\\n\\nAffective events BIBREF0 are...\n",
       "1   prompter  Keeping this in mind, answer the following que...\n",
       "2  assistant  - The seed lexicon consists of positive and ne..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qasper_texts_train.loc[qasper_indices_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The seed lexicon consists of positive and negative predicates. If the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, we assign the corresponding polarity score ($+1$ for positive events and $-1$ for negative events) to the event.\n",
      "- It is a \n",
      "\n",
      "a vocabulary of positive and negative predicates that helps determine the polarity score of an event\n"
     ]
    }
   ],
   "source": [
    "print(df_qasper_texts_train.loc[qasper_indices_train[0]][\"text\"].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- We compare our approaches with related approaches of pivoting, multilingual NMT (MNMT) BIBREF19, and cross-lingual transfer without pretraining BIBREF16. \n",
      "- The results show that our approaches consistently outperform other approaches across languages and datasets, especially surpass pivoting, which is a strong baseline in the zero-shot scenario that multilingual NMT systems often fail to beat BIBREF19, BIBREF20, BIBREF23.\n"
     ]
    }
   ],
   "source": [
    "print(df_qasper_texts_validation.loc[qasper_indices_validation[0]][\"text\"].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- In order to evaluate the models trained on generated data, we manually annotated a named entities dataset comprising 53453 tokens and 2566 sentences selected from over 250 news texts from ilur.am.\n"
     ]
    }
   ],
   "source": [
    "print(df_qasper_texts_validation.loc[qasper_indices_validation[10]][\"text\"].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6229"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qasper_indices_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_indices(indices, offset):\n",
    "    return [\n",
    "        [i + offset for i in row]\n",
    "        for row in indices\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "indices_train = []\n",
    "indices_validation = []\n",
    "sources_train = []\n",
    "sources_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train.append(shift_indices(\n",
    "    oasst1_indices_train,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_oasst1_texts_train)\n",
    "sources_train.append(\"openassistant\")\n",
    "\n",
    "indices_validation.append(shift_indices(\n",
    "    oasst1_indices_validation,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_oasst1_texts_validation)\n",
    "sources_validation.append(\"openassistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train.append(shift_indices(\n",
    "    alpaca_indices_train,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "sources_train.append(\"alpaca\")\n",
    "\n",
    "indices_validation.append(shift_indices(\n",
    "    alpaca_indices_validation,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "sources_validation.append(\"alpaca\")\n",
    "\n",
    "texts.append(df_alpaca_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train.append(shift_indices(\n",
    "    gpt4all_indices_train,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "sources_train.append(\"gpt4all\")\n",
    "\n",
    "indices_validation.append(shift_indices(\n",
    "    gpt4all_indices_validation,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "sources_validation.append(\"gpt4all\")\n",
    "\n",
    "texts.append(df_gpt4all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train.append(shift_indices(\n",
    "    booksum_indices_train,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_booksum_texts_train)\n",
    "sources_train.append(\"booksum\")\n",
    "\n",
    "indices_validation.append(shift_indices(\n",
    "    booksum_indices_validation,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_booksum_texts_validation)\n",
    "sources_validation.append(\"booksum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train.append(shift_indices(\n",
    "    govreport_indices_train,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_govreport_texts_train)\n",
    "sources_train.append(\"govreport\")\n",
    "\n",
    "indices_validation.append(shift_indices(\n",
    "    govreport_indices_validation,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_govreport_texts_validation)\n",
    "sources_validation.append(\"govreport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train.append(shift_indices(\n",
    "    qasper_indices_train,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_qasper_texts_train)\n",
    "sources_train.append(\"qasper\")\n",
    "\n",
    "indices_validation.append(shift_indices(\n",
    "    qasper_indices_validation,\n",
    "    sum(map(len, texts))\n",
    "))\n",
    "texts.append(df_qasper_texts_validation)\n",
    "sources_validation.append(\"qasper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_df(indices, sources):\n",
    "    rows = []\n",
    "    for ds_indices, ds_source in zip(indices, sources):\n",
    "        for row in ds_indices:\n",
    "            rows.append({\"indices\": row, \"source\": ds_source})\n",
    "    return pd.DataFrame.from_records(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices_train = get_indices_df(indices_train, sources_train)\n",
    "df_indices_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices_validation = get_indices_df(indices_validation, sources_validation)\n",
    "df_indices_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = pd.concat(texts).reset_index(drop=True)\n",
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices_train.groupby(\"source\").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[139334, 139335]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[825928, 825929]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[958912, 958913]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[983942, 983943]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[1022868, 1022869, 1022870]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices_validation.groupby(\"source\").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[82483, 82484]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[163170, 163171]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[705722, 705723]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[980974, 980975]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[1020922, 1020923]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.loc[[1036630, 1036631, 1036632]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"long-vicuna-set\", exist_ok=True)\n",
    "df_texts.to_csv(\"long-vicuna-set/texts.gz\", index=True, compression=\"gzip\")\n",
    "df_indices_train.to_pickle(\"long-vicuna-set/indices-train.pkl\")\n",
    "df_indices_validation.to_pickle(\"long-vicuna-set/indices-validation.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
